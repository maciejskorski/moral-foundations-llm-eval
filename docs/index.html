<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Estimating Human vs AI Moral Competences</title>
    <style>
        body { 
            font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, sans-serif; 
            max-width: 900px; 
            margin: 0 auto; 
            padding: 20px; 
            line-height: 1.6; 
            color: #333;
        }
        .badges { margin: 15px 0; }
        .badge { margin: 2px; }
        .chart { text-align: center; margin: 30px 0; }
        .chart img { max-width: 100%; height: auto; border-radius: 8px; box-shadow: 0 2px 10px rgba(0,0,0,0.1); }
        code { background: #f8f9fa; padding: 4px 8px; border-radius: 4px; font-family: 'Monaco', 'Courier New', monospace; }
        pre { background: #f8f9fa; padding: 15px; border-radius: 8px; overflow-x: auto; }
        .notebook { 
            background: #f8f9fa; 
            padding: 15px; 
            margin: 10px 0; 
            border-radius: 8px; 
            border-left: 4px solid #007acc;
        }
        .notebook h4 { margin: 0 0 8px 0; color: #007acc; }
        .finding { 
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            color: white;
            padding: 20px;
            border-radius: 12px;
            margin: 25px 0;
            text-align: center;
        }
        .links-container {
            display: flex;
            gap: 15px;
            flex-wrap: wrap;
            justify-content: center;
            margin: 25px 0;
        }
        .link-button {
            display: inline-flex;
            align-items: center;
            gap: 8px;
            padding: 12px 20px;
            text-decoration: none;
            border-radius: 8px;
            font-weight: 500;
            transition: all 0.3s ease;
            box-shadow: 0 2px 5px rgba(0,0,0,0.1);
        }
        .github-link {
            background: #24292e;
            color: white;
        }
        .github-link:hover { 
            background: #0366d6; 
            transform: translateY(-2px);
            box-shadow: 0 4px 10px rgba(0,0,0,0.2);
        }
        .arxiv-link {
            background: #b31b1b;
            color: white;
        }
        .arxiv-link:hover { 
            background: #d42c2c; 
            transform: translateY(-2px);
            box-shadow: 0 4px 10px rgba(0,0,0,0.2);
        }
        h1 { color: #2c3e50; }
        h2 { color: #34495e; border-bottom: 2px solid #eee; padding-bottom: 10px; }
    </style>
</head>
<body>
    <h1>üß† Estimating Human vs AI Moral Competences</h1>
    
    <div class="badges">
        <img src="https://img.shields.io/badge/Python-3.12+-blue.svg" class="badge">
        <img src="https://img.shields.io/badge/Jupyter-Notebook-orange.svg" class="badge">
        <img src="https://img.shields.io/badge/Papermill-Parameterized-green.svg" class="badge">
        <img src="https://img.shields.io/badge/TensorFlow-2.0+-orange.svg" class="badge">
        <img src="https://img.shields.io/badge/ü§ó-Datasets-yellow.svg" class="badge">
        <img src="https://img.shields.io/badge/Weights_&_Biases-FFBE00?logo=WeightsAndBiases&logoColor=white" class="badge">
    </div>

    <h2>üìã Overview</h2>
    <p><strong>Large-scale comprehensive evaluation of LLMs on moral reasoning using Haidt's Moral Foundations Theory and statistical modeling.</strong></p>

    <p>This project compares AI performance against human annotators across moral dimensions: care/harm, fairness/cheating, loyalty/betrayal, authority/subversion, and sanctity/degradation.</p>

    <div class="finding">
        <h3>üéØ Key Findings</h3>
        <p>AI models show more balanced predictions and much fewer false negatives (missed findings) compared to human annotators, achieving <strong>75th-100th percentile performance</strong> across moral foundations.</p>
    </div>

    <div class="chart">
        <h3>üìä AI vs Human Performance</h3>
        <div id="chart1" style="width: 100%;"></div>
        <p><em>Interactive performance rankings across moral dimensions</em></p>
    </div>

    <div class="chart">
        <h3>‚öñÔ∏è AI vs Human Errors</h3>
        <div id="chart2" style="width: 100%;"></div>
        <p><em>Interactive false positive and false negative rates comparison</em></p>
    </div>

    <script src="https://cdn.jsdelivr.net/npm/vega@5"></script>
    <script src="https://cdn.jsdelivr.net/npm/vega-lite@5"></script>
    <script src="https://cdn.jsdelivr.net/npm/vega-embed@6"></script>
    
    <script>
        // Load interactive charts
        vegaEmbed('#chart1', 'results/ai-rank.json').catch(() => {
            // Fallback to SVG if JSON not available
            document.getElementById('chart1').innerHTML = '<img src="results/ai-rank.svg" alt="AI vs Human Performance Rankings" style="max-width: 100%;">';
        });
        
        vegaEmbed('#chart2', 'results/ai-humans.json').catch(() => {
            // Fallback to SVG if JSON not available
            document.getElementById('chart2').innerHTML = '<img src="results/ai-humans.svg" alt="AI vs Human Error Analysis" style="max-width: 100%;">';
        });
    </script>

    <h2>üß™ Methodology</h2>
    
    <div class="notebook">
        <h4>Step 1: üìä Dataset Standardization</h4>
        <p>Standardize three moral psychology datasets (MFRC, MFTC, eMFD) into unified 5-foundation taxonomy. Clean annotations from multiple human annotators across Reddit, Twitter, and forum text domains.</p>
    </div>

    <div class="notebook">
        <h4>Step 2: ü§ñ LLM Evaluation</h4>
        <p>Evaluate multiple state-of-the-art language models (Claude-4, DeepSeek-V3, Llama4-Maverick) on moral foundation classification using standardized prompting and async batch processing.</p>
    </div>

    <div class="notebook">
        <h4>Step 3: üìà Competence Modeling</h4>
        <p>Apply novel GPU-efficient Dawid-Skene statistical model to estimate annotator competences, compare AI vs human performance, and generate percentile rankings across moral dimensions.</p>
    </div>

    <h2>‚öôÔ∏è Dependencies</h2>
    <p><code>datasets</code> <code>tensorflow</code> <code>anthropic</code> <code>openai</code> <code>replicate</code> <code>wandb</code> <code>papermill</code></p>

    <div class="links-container">
        <a href="https://github.com/maciejskorski/moral-foundations-llm-eval" class="link-button github-link">
            <span>üìÇ</span>
            <span>View Repository on GitHub</span>
        </a>
        <a href="https://arxiv.org/abs/2508.13804" class="link-button arxiv-link">
            <span>üìÑ</span>
            <span>View arXiv Paper</span>
        </a>
    </div>

    <footer style="margin-top: 50px; padding-top: 20px; border-top: 1px solid #eee; text-align: center; color: #666;">
        <p>Research on moral foundation classification and annotator competence modeling</p>
    </footer>
</body>
</html>